# Runbook - Data Mining

Guide d'exploitation pour le module Data Mining de l'ERP Distribution.

## üöÄ D√©marrage

### Installation initiale

```powershell
cd data_mining
copy .env.example .env
# √âditer .env avec vos identifiants PostgreSQL DWH
pip install -r requirements.txt
```

### Ex√©cution compl√®te

```powershell
cd data_mining
python run_mining.py
```

### Ex√©cution s√©lective

```powershell
# Analyse exploratoire uniquement
python run_mining.py --analysis exploratory

# Clustering uniquement
python run_mining.py --analysis clustering

# D√©tection anomalies uniquement
python run_mining.py --analysis anomaly

# Analyse RFM uniquement
python run_mining.py --analysis rfm

# Mode rapide (√©chantillon 10%)
python run_mining.py --quick
```

## üìã Pr√©requis

### Base de donn√©es
- PostgreSQL local d√©marr√©
- Base `erp_distribution_dwh` existante et peupl√©e
- Tables DWH avec donn√©es suffisantes (min 1000 commandes)

### Configuration (.env)
```env
DWH_PGHOST=localhost
DWH_PGPORT=5432
DWH_PGDATABASE=erp_distribution_dwh
DWH_PGUSER=postgres
DWH_PGPASSWORD=votre_mot_de_passe

MINING_RESULTS_PATH=results
MINING_PLOTS_PATH=results/plots
MINING_REPORTS_PATH=results/reports
```

### D√©pendances Python
```powershell
pip install pandas numpy psycopg2-binary scikit-learn matplotlib seaborn plotly jinja2
```

## üîß Utilisation

### Pipeline complet

Le pipeline ex√©cute les 4 analyses dans l'ordre :
1. **Analyse Exploratoire** : Statistiques et visualisations
2. **Clustering Clients** : Segmentation K-Means
3. **D√©tection Anomalies** : Isolation Forest
4. **Analyse RFM** : Segmentation R√©cence-Fr√©quence-Montant
5. **Rapport HTML** : Synth√®se compl√®te

### Sorties g√©n√©r√©es

#### Graphiques (results/plots/)
- `order_amounts_distribution.png` - Distribution montants commandes
- `sales_by_region.png` - Ventes par r√©gion
- `top_products.png` - Top produits par ventes
- `temporal_patterns.png` - Patterns temporels
- `correlation_matrix.png` - Matrice corr√©lation
- `clustering_optimal_k.png` - Optimisation nombre clusters
- `clustering_analysis.png` - Analyse clustering compl√®te
- `anomaly_detection.png` - Visualisation anomalies
- `rfm_analysis.png` - Analyse RFM
- `rfm_3d.png` - Vue 3D segments RFM

#### Donn√©es export√©es (results/data/)
- `orders_summary.csv` - R√©sum√© commandes
- `products_analysis.csv` - Analyse produits
- `temporal_patterns.csv` - Patterns temporels
- `customers_with_clusters.csv` - Clients avec clusters
- `cluster_statistics.csv` - Statistiques clusters
- `transactions_with_anomalies.csv` - Transactions avec anomalies
- `anomalies_only.csv` - Anomalies uniquement
- `rfm_analysis.csv` - Analyse RFM compl√®te
- `rfm_segments.csv` - Segments RFM

#### Rapports (results/reports/)
- `data_mining_report_YYYYMMDD_HHMMSS.html` - Rapport HTML complet

## üêõ D√©pannage

### Erreurs fr√©quentes

#### "Erreur de connexion PostgreSQL"
- **Cause** : Mauvais identifiants dans `.env`
- **Solution** : V√©rifier `DWH_PG*` variables, tester avec `psql`

#### "Pas assez de donn√©es"
- **Cause** : DWH vide ou trop peu de donn√©es
- **Solution** : Ex√©cuter `python ../BI/run_pipeline.py` pour peupler le DWH

#### "ModuleNotFoundError"
- **Cause** : D√©pendances manquantes
- **Solution** : `pip install -r requirements.txt`

#### "MemoryError"
- **Cause** : Dataset trop grand pour la RAM
- **Solution** : Utiliser `--quick` ou augmenter la RAM

#### "Erreur clustering"
- **Cause** : Pas assez de clients distincts
- **Solution** : Minimum 50 clients n√©cessaires pour K-Means

### V√©rifications post-ex√©cution

1. **Fichiers g√©n√©r√©s** : V√©rifier que `results/` contient les 3 sous-dossiers
2. **Graphiques** : Ouvrir quelques PNG pour v√©rifier la g√©n√©ration
3. **Donn√©es CSV** : V√©rifier que les fichiers ne sont pas vides
4. **Rapport HTML** : Ouvrir dans un navigateur pour validation

### Performance

#### Temps d'ex√©cution typiques
- **Mode complet** : 5-15 minutes (selon volume donn√©es)
- **Mode quick** : 1-3 minutes
- **Analyse unique** : 1-5 minutes

#### Optimisations
- **Mode quick** : √âchantillonnage 10% pour tests
- **Parall√©lisation** : Analyses ind√©pendantes possibles
- **Cache** : R√©utiliser les donn√©es entre analyses

## üìä Interpr√©tation des r√©sultats

### Clustering
- **Silhouette score** : > 0.5 = bonne segmentation
- **Nombre optimal** : Choisir selon m√©tier, pas seulement statistique
- **Profils clusters** : Interpr√©ter les caract√©ristiques moyennes

### Anomalies
- **Taux normal** : 1-5% de transactions anormales
- **Types** : Montants √©lev√©s, heures inhabituelles, quantit√©s √©tranges
- **Actions** : V√©rification manuelle des cas suspects

### RFM
- **Champions** : Meilleurs clients, √† conserver
- **Fid√®les** : Base stable, programmes fid√©lit√©
- **√Ä risque** : Campagnes r√©activation
- **Perdus** : Campagnes reconqu√™te

## üîÑ Maintenance

### Quotidienne
- V√©rifier l'espace disque (graphiques et donn√©es peuvent s'accumuler)
- Nettoyer les anciens r√©sultats si n√©cessaire

### Hebdomadaire
- Mettre √† jour les d√©pendances `pip update`
- V√©rifier les performances avec diff√©rents volumes de donn√©es

### Mensuelle
- Analyser les trends dans les r√©sultats
- Ajuster les param√®tres des algorithmes si n√©cessaire
- Archiver les anciens rapports

## üìû Support

Pour toute question :
1. Consulter ce runbook
2. V√©rifier les logs en console pour messages d'erreur d√©taill√©s
3. Tester avec `--quick` pour isoler les probl√®mes
4. Consulter la documentation technique dans `docs/architecture.md`
